{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda:\n",
    "[AlexNet](#AlexNet)  \n",
    "[simple ConvNet](#simple-ConvNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph();\n",
    "tf.reset_default_graph();\n",
    "input=tf.placeholder(tf.float32, (None, 3920), 'input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet\n",
    "The famous AlexNet [paper](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf).\n",
    "<img src=\"assets/AlexNet_architecture.png\" width=\"800\" />\n",
    "<img src=\"assets/cs231n_alexNet.png\" width=\"800\" />\n",
    "\n",
    "[tensorflow impletation](https://www.cs.toronto.edu/~guerzhoy/tf_alexnet/myalexnet_forward_newtf.py)\n",
    "in the following architecture:  \n",
    ".conv(11, 11, 96, 4, 4, padding='VALID', name='conv1')  \n",
    ".lrn(2, 2e-05, 0.75, name='norm1')  \n",
    ".max_pool(3, 3, 2, 2, padding='VALID', name='pool1')  \n",
    ".conv(5, 5, 256, 1, 1, group=2, name='conv2')  \n",
    ".lrn(2, 2e-05, 0.75, name='norm2')  \n",
    ".max_pool(3, 3, 2, 2, padding='VALID', name='pool2')  \n",
    ".conv(3, 3, 384, 1, 1, name='conv3')  \n",
    ".conv(3, 3, 384, 1, 1, group=2, name='conv4')  \n",
    ".conv(3, 3, 256, 1, 1, group=2, name='conv5')  \n",
    ".max_pool(3, 3, 2, 2, padding='VALID', name='pool3')  \n",
    ".fc(4096, name='fc6')  \n",
    ".fc(4096, name='fc7')  \n",
    ".fc(1000, relu=False, name='fc8')  \n",
    ".softmax(name='prob')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AlexNet(input, is_training):\n",
    "    #reshape to 2d [batch_size, 98, 40, 1]  name='reshape_input_1'\n",
    "    reshape_input_1 = tf.reshape(input, [-1, 98, 40, 1], 'reshape_input_1')\n",
    "    #conv(6, 3, 96, 2, 2, padding='VALID', name='conv_2')  \n",
    "    conv_2 = tf.layers.conv2d(reshape_input_1, 96, (6,3), (2,2), 'same', name='conv_2')\n",
    "\n",
    "    #lrn(2, 2e-05, 0.75, name='norm_3')  \n",
    "    norm_3 = tf.nn.local_response_normalization(conv_2, 2, None, 2e-05, 0.75, 'norm_3')\n",
    "\n",
    "    #max_pool(3, 2, 1, 1, padding='VALID', name='pool_4')  \n",
    "    pool_4 = tf.layers.max_pooling2d(norm_3, (3,2), (1,1), 'same', 'channels_last', 'pool_4')\n",
    "\n",
    "    #conv(3, 2, 256, 1, 1, group=2, name='conv_5')  \n",
    "    conv_5 = tf.layers.conv2d(pool_4, 256, (3,2), (1,1), 'same', name='conv_5')\n",
    "\n",
    "    #lrn(2, 2e-05, 0.75, name='norm_6')  \n",
    "    norm_6 = tf.nn.local_response_normalization(conv_5, 2, None, 2e-05, 0.75, 'norm_6')\n",
    "\n",
    "    #max_pool(3, 2, 1, 1, padding='VALID', name='pool_7')  \n",
    "    pool_7 = tf.layers.max_pooling2d(norm_6, (3,2), (1,1), 'same', 'channels_last', 'pool_7')\n",
    "\n",
    "    #conv(3, 2, 384, 1, 1, name='conv_8')  \n",
    "    conv_8 = tf.layers.conv2d(pool_7, 384, (3,2), (1,1), 'valid', name='conv_8')\n",
    "\n",
    "    #conv(3, 2, 384, 1, 1, group=2, name='conv_9')  \n",
    "    conv_9 = tf.layers.conv2d(conv_8, 384, (3,2), (1,1), 'valid', name='conv_9')\n",
    "\n",
    "    #conv(3, 2, 256, 1, 1, group=2, name='conv_10')  \n",
    "    conv_10 = tf.layers.conv2d(conv_9, 384, (3,2), (1,1), 'valid', name='conv_10')\n",
    "\n",
    "    #max_pool(3, 2, 2, 2, padding='VALID', name='pool_11')  \n",
    "    pool_11 = tf.layers.max_pooling2d(conv_10, (3,2), (2,2), 'valid', 'channels_last', 'pool_11')\n",
    "\n",
    "    #reshape to 1d [-1, ?] name='reshape_input_12'\n",
    "    size=int(pool_11.get_shape()[1]) * int(pool_11.get_shape()[2]) * int(pool_11.get_shape()[3])\n",
    "    reshape_input_12 = tf.reshape(pool_11, (-1, size), 'reshape_input_12')\n",
    "\n",
    "    #fc(1000, name='fc_13')  \n",
    "    fc_13 = tf.layers.dense(reshape_input_12, 1000, activation=tf.nn.relu, name='fc_13')\n",
    "\n",
    "    #fc(1000, name='fc_14')  \n",
    "    fc_14 = tf.layers.dense(fc_13, 1000, activation=tf.nn.relu, name='fc_14')\n",
    "\n",
    "    #fc(12, relu=False, name='fc_15')  \n",
    "    fc_15 = tf.layers.dense(fc_14, 12, activation=None, name='fc_15')\n",
    "\n",
    "    #softmax(name='prob_16'))  \n",
    "    prob_16 = tf.nn.softmax(fc_15, name='prob_16')\n",
    "    \n",
    "    return prob_16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training result for AlexNet:\n",
    "```\n",
    "Step 0.000000, loss: 2.484012, accurancy: 0.120000.\n",
    "Step 1.000000, loss: 2.485092, accurancy: 0.120000.\n",
    "Step 2.000000, loss: 2.484010, accurancy: 0.060000.\n",
    "Step 3.000000, loss: 2.485292, accurancy: 0.080000.\n",
    "Step 4.000000, loss: 2.484657, accurancy: 0.140000.\n",
    "Step 5.000000, loss: 2.485170, accurancy: 0.050000.\n",
    "Step 6.000000, loss: 2.484865, accurancy: 0.080000.\n",
    "Step 7.000000, loss: 2.484811, accurancy: 0.090000.\n",
    "Step 8.000000, loss: 2.485102, accurancy: 0.110000.\n",
    "Step 9.000000, loss: 2.486204, accurancy: 0.070000.\n",
    "Step 10.000000, loss: 2.484865, accurancy: 0.120000.\n",
    "Step 11.000000, loss: 2.484856, accurancy: 0.070000.\n",
    "Step 12.000000, loss: 2.485339, accurancy: 0.060000.\n",
    "Step 13.000000, loss: 2.483910, accurancy: 0.120000.\n",
    "Step 14.000000, loss: 2.485012, accurancy: 0.130000.\n",
    "Step 15.000000, loss: 2.484593, accurancy: 0.110000.\n",
    "Step 16.000000, loss: 2.484843, accurancy: 0.070000.\n",
    "Step 17.000000, loss: 2.485991, accurancy: 0.090000.\n",
    "Step 18.000000, loss: 2.483060, accurancy: 0.070000.\n",
    "Step 19.000000, loss: 2.485357, accurancy: 0.040000.\n",
    "```\n",
    "AlexNet is too deep for the feature in shape (98,40), \n",
    "the training can't learn anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"simple-ConvNet\">Simple ConvNet<h2/>\n",
    "Inspired by [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/speech_commands/models.py#L273)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleConvNet(input, is_training=True, dropout_prob=0.5):\n",
    "    \"\"\"\n",
    "    architecture as below:\n",
    "     [Conv2D]<-(weights)\n",
    "          v\n",
    "      [BiasAdd]<-(bias)\n",
    "          v\n",
    "        [Relu]\n",
    "          v\n",
    "      [MatMul]<-(weights)\n",
    "          v\n",
    "      [BiasAdd]<-(bias)\n",
    "          v\n",
    "      [MatMul]<-(weights)\n",
    "          v\n",
    "      [BiasAdd]<-(bias)\n",
    "          v\n",
    "      [MatMul]<-(weights)\n",
    "          v\n",
    "      [BiasAdd]<-(bias)\n",
    "      \n",
    "    output is the logits in shape (batch_size, 12)\n",
    "    \"\"\"\n",
    "    reshape_input_1 = tf.reshape(input, [-1, 98, 40, 1], 'reshape_input_1')\n",
    "    conv_2 = tf.layers.conv2d(reshape_input_1, 186, (98,8), (1,1), 'valid', name='conv_2')\n",
    "    relu_3 = tf.nn.relu(conv_2,'relu_3')\n",
    "    if is_training:\n",
    "        relu_3 = tf.nn.dropout(relu_3, dropout_prob, name = 'dropout')\n",
    "    size=int(relu_3.get_shape()[1]) * int(relu_3.get_shape()[2]) * int(relu_3.get_shape()[3])\n",
    "    relu_3 = tf.reshape(relu_3, (-1, size), 'reshape_relu_3')\n",
    "    fc_4 = tf.layers.dense(relu_3, 128,name = 'fc_4')\n",
    "    fc_5 = tf.layers.dense(fc_4, 128,name = 'fc_5')\n",
    "    logits = tf.layers.dense(fc_5, 12,name = 'logits')\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"simpleConvNet\"\n",
    "if model_name == \"AlexNet\":\n",
    "    logits = AlexNet(input)\n",
    "elif model_name = \"simpleConvNet\":\n",
    "    logits = simpleConvNet(input, is_training=True, dropout_prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training steps\n",
    "ground_truth_input = tf.placeholder(tf.int64, [None], name='groundtruth_input')\n",
    "learning_rate_input = tf.placeholder(tf.float32, [], name='learning_rate_input')\n",
    "cross_entropy_mean = tf.losses.sparse_softmax_cross_entropy(ground_truth_input, logits)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate_input).minimize(cross_entropy_mean)\n",
    "\n",
    "predicted_indices = tf.argmax(logits, 1)\n",
    "correct_prediction = tf.equal(predicted_indices, ground_truth_input)\n",
    "confusion_matrix = tf.confusion_matrix(ground_truth_input, predicted_indices, num_classes=12)\n",
    "evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training data\n",
    "data_dir = \"/Users/user/Desktop/git/TensorFlow_Speech_Recognition_Challenge/data/\"\n",
    "train_fingerprints=np.load(data_dir+\"train_fingerprints.npy\")\n",
    "train_ground_truth=np.load(data_dir+\"train_ground_truth.npy\")\n",
    "validate_fingerprints=np.load(data_dir+\"validate_fingerprints.npy\")\n",
    "validate_ground_truth=np.load(data_dir+\"validate_ground_truth.npy\")\n",
    "size=train_ground_truth.shape[0]\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "learning_rate = 1e-3\n",
    "learning_decay = 0.9\n",
    "learning_decay_period = 1000\n",
    "eval_every_steps = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(1, training_steps+1):\n",
    "        start_pos = (i-1) * batch_size % size\n",
    "        end_pos = (i-1) * batch_size % size + batch_size \n",
    "        loss, _ ,accurancy,  = sess.run([cross_entropy_mean, train_step, evaluation_step], \\\n",
    "                feed_dict={\n",
    "                    input: train_fingerprints[start_pos:end_pos],\n",
    "                    ground_truth_input: train_ground_truth[start_pos:end_pos],\n",
    "                    learning_rate_input: learning_rate * (learning_decay**(i // learning_decay_period))\n",
    "                })\n",
    "        print(\"Step %f, loss: %f, accurancy: %f.\" % (i, loss, accurancy))\n",
    "        if  i % eval_every_steps == 0:\n",
    "            saver.save(sess, data_dir + model_name +\".ckpt\", global_step=i)\n",
    "            accurancy = sess.run([evaluation_step], \\\n",
    "                feed_dict={\n",
    "                    input: validate_fingerprints,\n",
    "                    ground_truth_input: validate_ground_truth\n",
    "                })\n",
    "            print(\"Validation accurancy is %f\" % accurancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval on test data\n",
    "model_name = \"simpleConvNet\"\n",
    "if model_name == \"AlexNet\":\n",
    "    logits = AlexNet(input)\n",
    "elif model_name = \"simpleConvNet\":\n",
    "    logits = simpleConvNet(input, is_training=False, dropout_prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fingerprints=np.load(data_dir+\"test_fingerprints.npy\")\n",
    "test_ground_truth=np.load(data_dir+\"test_ground_truth.npy\")\n",
    "with tf.Session() as sess:\n",
    "    accurancy = sess.run([evaluation_step], \\\n",
    "        feed_dict={\n",
    "            input: test_fingerprints,\n",
    "            ground_truth_input: test_ground_truth\n",
    "        })\n",
    "    print(\"Test accurancy is %f\" % accurancy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification:  \n",
    "```\n",
    "'_silence_',\n",
    "'_unknown_',\n",
    "'yes',\n",
    "'no',\n",
    "'up',\n",
    "'down',\n",
    "'left',\n",
    "'right',\n",
    "'on',\n",
    "'off',\n",
    "'stop',\n",
    "'go'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #audio data exploration\n",
    "# from scipy.io import wavfile\n",
    "\n",
    "# sample_rate, samples = wavfile.read(\"../data/test/audio/clip_ff72c4530.wav\")\n",
    "\n",
    "# from scipy import signal\n",
    "# import numpy as np\n",
    "# def log_specgram(audio, sample_rate, window_size=20,\n",
    "#                  step_size=10, eps=1e-10):\n",
    "#     nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "#     noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "#     freqs, times, spec = signal.spectrogram(audio,\n",
    "#                                     fs=sample_rate,\n",
    "#                                     window='hann',\n",
    "#                                     nperseg=nperseg,\n",
    "#                                     noverlap=noverlap,\n",
    "#                                     detrend=False)\n",
    "#     return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
    "\n",
    "# freqs, times, spectrogram = log_specgram(samples, sample_rate)\n",
    "\n",
    "# spectrogram.shape\n",
    "\n",
    "# import librosa\n",
    "\n",
    "# S = librosa.feature.melspectrogram(samples, sr=sample_rate, n_mels=128)\n",
    "\n",
    "# S.shape\n",
    "\n",
    "# log_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "# log_S.shape\n",
    "\n",
    "# mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=13)\n",
    "\n",
    "# mfcc.shape\n",
    "\n",
    "# delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "# delta2_mfcc.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
