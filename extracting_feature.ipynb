{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/maikfangogoair/tensorflow/tensorflow/examples/speech_commands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "\n",
    "import input_data\n",
    "import models\n",
    "from tensorflow.python.platform import gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_words=\"yes,no,up,down,left,right,on,off,stop,go\"\n",
    "sample_rate=16000#Expected sample rate of the wavs\n",
    "clip_duration_ms=1000#Expected duration in milliseconds of the wavs\n",
    "window_size_ms=30.0#How long each spectrogram timeslice is\n",
    "window_stride_ms=10.0#How long each spectrogram timeslice is\n",
    "dct_coefficient_count=40#How many bins to use for the MFCC fingerprint\n",
    "data_url=\"http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz\"\n",
    "data_dir=\"/home/maikfangogoair/tmp\"\n",
    "silence_percentage=10.0 #How much of the training data should be silence.\n",
    "unknown_percentage=10.0 #How much of the training data should be unknown words.\n",
    "validation_percentage=10 #What percentage of wavs to use as a validation set.\n",
    "testing_percentage=10 #What percentage of wavs to use as a test set.\n",
    "time_shift_ms=100.0 #Range to randomly shift the training audio by in time.\n",
    "batch_size=100\n",
    "background_frequency=0.8#How many of the training samples have background noise mixed in.\n",
    "background_volume=0.1#How loud the background noise should be, between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 98\n"
     ]
    }
   ],
   "source": [
    "model_settings = models.prepare_model_settings(\n",
    "    len(input_data.prepare_words_list(wanted_words.split(','))),\n",
    "    sample_rate, clip_duration_ms, window_size_ms,\n",
    "    window_stride_ms, dct_coefficient_count)\n",
    "audio_processor = input_data.AudioProcessor(\n",
    "    data_url, data_dir, silence_percentage,\n",
    "    unknown_percentage,\n",
    "    wanted_words.split(','), validation_percentage,\n",
    "    testing_percentage, model_settings)\n",
    "fingerprint_size = model_settings['fingerprint_size']\n",
    "label_count = model_settings['label_count']\n",
    "time_shift_samples = int((time_shift_ms * sample_rate) / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3920\n",
      "12\n",
      "1600\n",
      "{'fingerprint_size': 3920, 'spectrogram_length': 98, 'dct_coefficient_count': 40, 'window_size_samples': 480, 'window_stride_samples': 160, 'sample_rate': 16000, 'label_count': 12, 'desired_samples': 16000}\n",
      "22246\n",
      "3093\n",
      "3081\n"
     ]
    }
   ],
   "source": [
    "print(fingerprint_size)\n",
    "print(label_count)\n",
    "print(time_shift_samples)\n",
    "print(model_settings)\n",
    "print(audio_processor.set_size(\"training\"))\n",
    "print(audio_processor.set_size(\"validation\"))\n",
    "print(audio_processor.set_size(\"testing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fingerprints, train_ground_truth = audio_processor.get_data(\n",
    "    audio_processor.set_size(\"training\"), 0, model_settings, background_frequency,\n",
    "    background_volume, time_shift_samples, 'training', sess)\n",
    "validation_fingerprints, validation_ground_truth = (\n",
    "            audio_processor.get_data(audio_processor.set_size(\"validation\"), 0, model_settings, 0.0,\n",
    "                                     0.0, 0, 'validation', sess))\n",
    "test_fingerprints, test_ground_truth = audio_processor.get_data(\n",
    "    audio_processor.set_size(\"testing\"), 0, model_settings, 0.0, 0.0, 0, 'testing', sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22246\n",
      "3093\n",
      "3081\n"
     ]
    }
   ],
   "source": [
    "print(train_fingerprints.shape[0])\n",
    "print(validation_fingerprints.shape[0])\n",
    "print(test_fingerprints.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"/home/maikfangogoair/tmp/\"\n",
    "np.save(dir+\"train_fingerprints.npy\",train_fingerprints)\n",
    "np.save(dir+\"train_ground_truth.npy\",train_ground_truth)\n",
    "np.save(dir+\"validation_fingerprints.npy\",validation_fingerprints)\n",
    "np.save(dir+\"validation_ground_truth.npy\",validation_ground_truth)\n",
    "np.save(dir+\"test_fingerprints.npy\",test_fingerprints)\n",
    "np.save(dir+\"test_ground_truth.npy\",test_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_silence_', '_unknown_', 'yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
      "{'zero': 1, 'nine': 1, 'house': 1, 'left': 6, 'two': 1, 'on': 8, 'down': 5, 'marvin': 1, 'up': 4, 'three': 1, 'no': 3, 'happy': 1, 'bed': 1, '_silence_': 0, 'tree': 1, 'wow': 1, 'cat': 1, 'sheila': 1, 'seven': 1, 'five': 1, 'four': 1, 'one': 1, 'six': 1, 'dog': 1, 'go': 11, 'yes': 2, 'stop': 10, 'right': 7, 'eight': 1, 'bird': 1, 'off': 9}\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(audio_processor.words_list)\n",
    "print(audio_processor.word_to_index)\n",
    "print(len(audio_processor.background_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22246\n",
      "(22246,)\n"
     ]
    }
   ],
   "source": [
    "print(len(audio_processor.data_index['training']))\n",
    "print(train_ground_truth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bird', 'no', 'no', 'go', 'no', '_silence_', 'down', 'happy', 'right', 'no']\n",
      "[  9.   1.   8.   7.   3.   2.  11.   4.   3.   3.]\n"
     ]
    }
   ],
   "source": [
    "print([x['label']for x in audio_processor.data_index['training'][:10]])\n",
    "print(train_ground_truth[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
